"""Обучим нейронную сеть для задачи регрессии:

Возьмем более сложную функцию в качестве таргета: y=2^x sin(2^{-x})y=2 
x
 sin(2 
−x
 ).

Кроме того, мы хотим получить хорошую метрику MAE на валидации: {MAE} = {\frac {1}{l}}\sum _{i=1}^{l}{|y\_pred_{i}-{y\_target_{i}}|}MAE= 
l
1
​	
 ∑ 
i=1
l
​	
 ∣y_pred 
i
​	
 −y_target 
i
​	
 ∣, тогда как знакомая нам MSE выглядит как {MSE} = {\frac {1}{l}}\sum _{i=1}^{l}(y\_pred_{i}-{y\_target_{i}})^{2}MSE= 
l
1
​	
 ∑ 
i=1
l
​	
 (y_pred 
i
​	
 −y_target 
i
​	
 ) 
2
 
Вот пример того, как нейросеть может отрабатывать на данной функции:
"""

import torch
#import matplotlib.pyplot as plt
#import matplotlib
#matplotlib.rcParams['figure.figsize'] = (13.0, 5.0)

def target_function(x):
    return 2**x * torch.sin(2**-x)

# ------Dataset preparation start--------:
x_train =  torch.linspace(-10, 5, 100)
y_train = target_function(x_train)
noise = torch.randn(y_train.shape) / 20.
y_train = y_train + noise
x_train.unsqueeze_(1)
y_train.unsqueeze_(1)

x_validation = torch.linspace(-10, 5, 100)
y_validation = target_function(x_validation)
x_validation.unsqueeze_(1)
y_validation.unsqueeze_(1)
# ------Dataset preparation end--------:

class RegressionNet(torch.nn.Module):
    def __init__(self, n_hidden_neurons):
        super(RegressionNet, self).__init__()
        self.fc1 = torch.nn.Linear(1, n_hidden_neurons)
        self.act1 = torch.nn.Tanh()
        self.fc2 = torch.nn.Linear(n_hidden_neurons, 1)
    def forward(self, x):
        x = self.fc1(x)
        x = self.act1(x)
        x = self.fc2(x)
        return x

net = RegressionNet(20)

optimizer = torch.optim.Adam(net.parameters(), lr=0.01)

def loss(pred, target):
    squares = (pred - target) ** 2
    return squares.mean()

for epoch_index in range(1000):
    optimizer.zero_grad()
    y_pred = net.forward(x_train)
    loss_value = loss(y_pred, y_train)
    loss_value.backward()
    optimizer.step()

#def predict(net, x, y):
#    y_pred = net.forward(x)
#    plt.plot(x.numpy(), y.numpy(), 'o', label='Groud truth')
#    plt.plot(x.numpy(), y_pred.data.numpy(), 'o', c='r', label='Prediction');
#    plt.legend(loc='upper left')
#    plt.xlabel('$x$')
#    plt.ylabel('$y$')

#predict(net, x_validation, y_validation)

#def metric(pred, target):
#    return (pred - target).abs().mean()

#print(metric(net.forward(x_validation), y_validation).item())
